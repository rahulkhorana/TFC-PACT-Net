{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqYoTBJrCcJx",
        "outputId": "a9ab01c3-e644-432a-a5a2-8391529e8565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.11/dist-packages (2025.3.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.1.2->aiohttp->torch_geometric) (4.14.1)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt26cu124)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric rdkit\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__)\").html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "M0suAYOT5R-N"
      },
      "outputs": [],
      "source": [
        "# Standard library\n",
        "from collections import defaultdict\n",
        "from typing import List, Tuple\n",
        "import importlib.resources as pkg_resources\n",
        "from multiprocessing.pool import ThreadPool\n",
        "\n",
        "# Third-party scientific stack\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import coo_matrix\n",
        "from scipy.sparse.linalg import eigsh\n",
        "\n",
        "# RDKit\n",
        "from rdkit import Chem\n",
        "\n",
        "# PyTorch core\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# PyTorch Geometric\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data, Batch, DataLoader\n",
        "from torch_geometric.nn import GCNConv, GINConv, BatchNorm, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader as PyGDataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wginy3UChb_",
        "outputId": "4eb954ad-ccaf-44ef-923e-b01a753e5f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "obXQxOveCM9l"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Fix all random seeds for reproducibility across Python, NumPy, and PyTorch.\n",
        "    \"\"\"\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(59)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fYyEoAXuCM9m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import (\n",
        "    PNAConv,\n",
        "    global_mean_pool,\n",
        "    global_max_pool,\n",
        "    global_add_pool\n",
        ")\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "class PolyatomicNet(nn.Module):\n",
        "    def __init__(self, node_feat_dim, edge_feat_dim, graph_feat_dim,deg,\n",
        "                 hidden_dim=128, num_layers=5, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.node_emb = nn.Linear(node_feat_dim, hidden_dim)\n",
        "        self.deg = deg\n",
        "        self.virtualnode_emb = nn.Embedding(1, hidden_dim)\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # For graph-level feature projection\n",
        "        self.graph_proj = nn.Sequential(\n",
        "            nn.Linear(graph_feat_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # PNAConv requires degree preprocessing\n",
        "        self.deg_emb = nn.Embedding(20, hidden_dim)  # cap degree buckets\n",
        "\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            conv = PNAConv(\n",
        "                in_channels=hidden_dim,\n",
        "                out_channels=hidden_dim,\n",
        "                aggregators=aggregators,\n",
        "                scalers=scalers,\n",
        "                edge_dim=edge_feat_dim,\n",
        "                towers=4,\n",
        "                pre_layers=1,\n",
        "                post_layers=1,\n",
        "                divide_input=True,\n",
        "                deg=deg\n",
        "            )\n",
        "            self.convs.append(conv)\n",
        "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Final readout\n",
        "        self.readout = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 3, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 2, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr, batch = (\n",
        "            data.x,\n",
        "            data.edge_index,\n",
        "            data.edge_attr,\n",
        "            data.batch,\n",
        "        )\n",
        "\n",
        "        deg = degree(edge_index[0], x.size(0), dtype=torch.long).clamp(max=19)\n",
        "        h = self.node_emb(x) + self.deg_emb(deg)\n",
        "\n",
        "        vn = self.virtualnode_emb(\n",
        "            torch.zeros(batch.max().item() + 1, dtype=torch.long, device=x.device)\n",
        "        )\n",
        "\n",
        "        for conv, bn in zip(self.convs, self.bns):\n",
        "            h = h + vn[batch]\n",
        "            h = conv(h, edge_index, edge_attr)\n",
        "            h = bn(h)\n",
        "            h = F.relu(h)\n",
        "            h = self.dropout(h)\n",
        "            vn = vn + self.vn_mlp(global_mean_pool(h, batch))\n",
        "\n",
        "        mean_pool = global_mean_pool(h, batch)\n",
        "        max_pool  = global_max_pool(h, batch)\n",
        "        add_pool  = global_add_pool(h, batch)\n",
        "\n",
        "        # graph_feats shape: [batch_size, graph_feat_dim]\n",
        "        if hasattr(data, 'graph_feats') and isinstance(data, torch_geometric.data.Batch):\n",
        "            g_feats = torch.stack([g.graph_feats for g in data.to_data_list()], dim=0).to(x.device)\n",
        "        else:\n",
        "            g_feats = data.graph_feats.unsqueeze(0).to(x.device)  # handles single graph batch\n",
        "        g_proj = self.graph_proj(g_feats)\n",
        "\n",
        "        final_input = torch.cat([mean_pool, max_pool, g_proj], dim=1)\n",
        "        return self.readout(final_input).view(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "daTRiHSFCM9m"
      },
      "outputs": [],
      "source": [
        "from torch.amp import autocast, GradScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "scaler_grad = GradScaler()\n",
        "\n",
        "def train(model, loader, optimizer, loss_fn, scaler=scaler_grad, accum_steps=8):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, batch in enumerate(loader):\n",
        "        batch = batch.to(device)\n",
        "        with autocast(device_type='cuda', dtype=torch.float16):\n",
        "            output = model(batch)\n",
        "            loss = loss_fn(output, batch.y.view(-1)) / accum_steps\n",
        "\n",
        "        scaler_grad.scale(loss).backward()\n",
        "\n",
        "        if (i + 1) % accum_steps == 0 or (i + 1 == len(loader)):\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item() * batch.num_graphs * accum_steps\n",
        "\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def compute_metrics_with_ci(trues, preds, n_boot=2000, alpha=0.05, seed=42):\n",
        "    trues = np.array(trues)\n",
        "    preds = np.array(preds)\n",
        "    mae = mean_absolute_error(trues, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "\n",
        "    rng = np.random.RandomState(seed)\n",
        "    mae_samples, rmse_samples = [], []\n",
        "    n = len(trues)\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.randint(0, n, n)\n",
        "        t, p = trues[idx], preds[idx]\n",
        "        mae_samples.append(mean_absolute_error(t, p))\n",
        "        rmse_samples.append(np.sqrt(mean_squared_error(t, p)))\n",
        "\n",
        "    lower, upper = 100 * alpha / 2, 100 * (1 - alpha / 2)\n",
        "    mae_ci = (np.percentile(mae_samples, lower), np.percentile(mae_samples, upper))\n",
        "    rmse_ci = (np.percentile(rmse_samples, lower), np.percentile(rmse_samples, upper))\n",
        "    return {'mae': mae, 'mae_ci': mae_ci, 'rmse': rmse, 'rmse_ci': rmse_ci}\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad(), autocast(device_type='cuda', dtype=torch.float16):\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch)\n",
        "            preds.append(out.view(-1))\n",
        "            trues.append(batch.y.view(-1))\n",
        "    preds = torch.cat(preds)\n",
        "    trues = torch.cat(trues)\n",
        "    return torch.sqrt(torch.mean((preds - trues) ** 2)).item()\n",
        "\n",
        "def evaluate_with_ci(model, loader):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad(), autocast(device_type='cuda', dtype=torch.float16):\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch)\n",
        "            y_true = batch.y.view(-1).cpu().tolist()\n",
        "            y_pred = out.view(-1).cpu().tolist()\n",
        "            trues.extend(y_true)\n",
        "            preds.extend(y_pred)\n",
        "    return compute_metrics_with_ci(trues, preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "b7jK5FEjCM9m"
      },
      "outputs": [],
      "source": [
        "loading = True\n",
        "if loading:\n",
        "    all_data = torch.load('/content/drive/MyDrive/richer_lipophil_data.pt', weights_only=False)\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    ys = np.array([d.y.item() for d in all_data]).reshape(-1, 1)\n",
        "    ys_scaled = scaler.fit_transform(ys)\n",
        "    for i, d in enumerate(all_data):\n",
        "        d.y = torch.tensor([ys_scaled[i][0]], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aT9Ljr-SgTsE"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*An output with one or more elements was resized.*\")\n",
        "warnings.filterwarnings(\"ignore\", message=\".*FutureWarning:.*\")\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.optim.lr_scheduler\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_ZBbQn-98XEu"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "data_list = all_data\n",
        "train_n = int(0.8 * len(data_list))\n",
        "train_ds, test_ds = torch.utils.data.random_split(\n",
        "    data_list, [train_n, len(data_list)-train_n]\n",
        ")\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=8, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=16)\n",
        "\n",
        "node_feat_dim = all_data[0].x.shape[1]\n",
        "edge_feat_dim = all_data[0].edge_attr.shape[1]\n",
        "graph_feat_dim = all_data[0].graph_feats.shape[0]\n",
        "\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "deg = torch.zeros(128, dtype=torch.long)  # increase if needed\n",
        "\n",
        "for data in train_ds:\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    bc = torch.bincount(d, minlength=deg.size(0))\n",
        "    if bc.size(0) > deg.size(0):\n",
        "        # Expand deg to fit\n",
        "        new_deg = torch.zeros(bc.size(0), dtype=torch.long)\n",
        "        new_deg[:deg.size(0)] = deg\n",
        "        deg = new_deg\n",
        "    deg += bc\n",
        "\n",
        "model = PolyatomicNet(\n",
        "    node_feat_dim=node_feat_dim,\n",
        "    edge_feat_dim=edge_feat_dim,\n",
        "    graph_feat_dim=graph_feat_dim,\n",
        "    deg=deg,\n",
        ")\n",
        "\n",
        "input_dim = all_data[0].x.size(1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', patience=10, factor=0.5, verbose=True\n",
        ")\n",
        "loss_fn   = nn.SmoothL1Loss(beta=0.5)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XchdS-ZoCM9m",
        "outputId": "08d663fd-09d9-4dcf-c124-c3d3b3fa8358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train Loss: 0.5823 | Test MAE: 0.7931 (95% CI [0.7541, 0.8303]) | Test RMSE: 0.9812 (95% CI [0.9367, 1.0256])\n",
            "Epoch 02 | Train Loss: 0.5486 | Test MAE: 0.7720 (95% CI [0.7321, 0.8118]) | Test RMSE: 0.9843 (95% CI [0.9358, 1.0330])\n",
            "Epoch 03 | Train Loss: 0.5261 | Test MAE: 0.7696 (95% CI [0.7329, 0.8058]) | Test RMSE: 0.9461 (95% CI [0.9055, 0.9876])\n",
            "Epoch 04 | Train Loss: 0.5034 | Test MAE: 0.7464 (95% CI [0.7105, 0.7828]) | Test RMSE: 0.9097 (95% CI [0.8692, 0.9510])\n",
            "Epoch 05 | Train Loss: 0.4910 | Test MAE: 0.7100 (95% CI [0.6742, 0.7487]) | Test RMSE: 0.9000 (95% CI [0.8542, 0.9489])\n",
            "Epoch 06 | Train Loss: 0.4696 | Test MAE: 0.6634 (95% CI [0.6294, 0.6988]) | Test RMSE: 0.8366 (95% CI [0.7934, 0.8830])\n",
            "Epoch 07 | Train Loss: 0.4583 | Test MAE: 0.6822 (95% CI [0.6484, 0.7171]) | Test RMSE: 0.8518 (95% CI [0.8094, 0.8949])\n",
            "Epoch 08 | Train Loss: 0.4561 | Test MAE: 0.7700 (95% CI [0.7285, 0.8145]) | Test RMSE: 1.0046 (95% CI [0.9482, 1.0589])\n",
            "Epoch 09 | Train Loss: 0.4498 | Test MAE: 0.6706 (95% CI [0.6350, 0.7060]) | Test RMSE: 0.8450 (95% CI [0.7998, 0.8942])\n",
            "Epoch 10 | Train Loss: 0.4084 | Test MAE: 0.7123 (95% CI [0.6773, 0.7486]) | Test RMSE: 0.8823 (95% CI [0.8397, 0.9304])\n",
            "Epoch 11 | Train Loss: 0.3989 | Test MAE: 0.6240 (95% CI [0.5918, 0.6568]) | Test RMSE: 0.7876 (95% CI [0.7473, 0.8286])\n",
            "Epoch 12 | Train Loss: 0.3885 | Test MAE: 0.6446 (95% CI [0.6132, 0.6786]) | Test RMSE: 0.7940 (95% CI [0.7577, 0.8323])\n",
            "Epoch 13 | Train Loss: 0.3798 | Test MAE: 0.6900 (95% CI [0.6584, 0.7231]) | Test RMSE: 0.8344 (95% CI [0.7981, 0.8709])\n",
            "Epoch 14 | Train Loss: 0.3630 | Test MAE: 0.5640 (95% CI [0.5348, 0.5952]) | Test RMSE: 0.7188 (95% CI [0.6800, 0.7600])\n",
            "Epoch 15 | Train Loss: 0.3565 | Test MAE: 0.6233 (95% CI [0.5947, 0.6544]) | Test RMSE: 0.7669 (95% CI [0.7319, 0.8034])\n",
            "Epoch 16 | Train Loss: 0.3529 | Test MAE: 0.5629 (95% CI [0.5302, 0.5967]) | Test RMSE: 0.7424 (95% CI [0.6969, 0.7901])\n",
            "Epoch 17 | Train Loss: 0.3348 | Test MAE: 0.5556 (95% CI [0.5252, 0.5872]) | Test RMSE: 0.7070 (95% CI [0.6684, 0.7467])\n",
            "Epoch 18 | Train Loss: 0.3193 | Test MAE: 0.5491 (95% CI [0.5200, 0.5787]) | Test RMSE: 0.7009 (95% CI [0.6629, 0.7400])\n",
            "Epoch 19 | Train Loss: 0.3271 | Test MAE: 0.5189 (95% CI [0.4902, 0.5490]) | Test RMSE: 0.6790 (95% CI [0.6405, 0.7188])\n",
            "Epoch 20 | Train Loss: 0.3218 | Test MAE: 0.5694 (95% CI [0.5396, 0.6013]) | Test RMSE: 0.7298 (95% CI [0.6906, 0.7728])\n",
            "Epoch 21 | Train Loss: 0.3139 | Test MAE: 0.5845 (95% CI [0.5547, 0.6140]) | Test RMSE: 0.7356 (95% CI [0.6985, 0.7753])\n",
            "Epoch 22 | Train Loss: 0.3066 | Test MAE: 0.5082 (95% CI [0.4805, 0.5367]) | Test RMSE: 0.6618 (95% CI [0.6234, 0.7031])\n",
            "Epoch 23 | Train Loss: 0.2939 | Test MAE: 0.4698 (95% CI [0.4421, 0.5004]) | Test RMSE: 0.6282 (95% CI [0.5878, 0.6734])\n",
            "Epoch 24 | Train Loss: 0.3045 | Test MAE: 0.5176 (95% CI [0.4884, 0.5487]) | Test RMSE: 0.6782 (95% CI [0.6387, 0.7215])\n",
            "Epoch 25 | Train Loss: 0.3001 | Test MAE: 0.4877 (95% CI [0.4593, 0.5160]) | Test RMSE: 0.6427 (95% CI [0.6024, 0.6846])\n",
            "Epoch 26 | Train Loss: 0.2841 | Test MAE: 0.7058 (95% CI [0.6738, 0.7371]) | Test RMSE: 0.8484 (95% CI [0.8123, 0.8855])\n",
            "Epoch 27 | Train Loss: 0.2996 | Test MAE: 0.6119 (95% CI [0.5822, 0.6420]) | Test RMSE: 0.7625 (95% CI [0.7251, 0.8002])\n",
            "Epoch 28 | Train Loss: 0.2879 | Test MAE: 0.5140 (95% CI [0.4870, 0.5437]) | Test RMSE: 0.6574 (95% CI [0.6205, 0.6976])\n",
            "Epoch 29 | Train Loss: 0.2849 | Test MAE: 0.6588 (95% CI [0.6280, 0.6945]) | Test RMSE: 0.8245 (95% CI [0.7840, 0.8693])\n",
            "Epoch 30 | Train Loss: 0.2845 | Test MAE: 0.5029 (95% CI [0.4733, 0.5337]) | Test RMSE: 0.6633 (95% CI [0.6248, 0.7061])\n",
            "Epoch 31 | Train Loss: 0.2727 | Test MAE: 0.6008 (95% CI [0.5717, 0.6317]) | Test RMSE: 0.7431 (95% CI [0.7073, 0.7802])\n",
            "Epoch 32 | Train Loss: 0.2666 | Test MAE: 0.5309 (95% CI [0.5019, 0.5620]) | Test RMSE: 0.6918 (95% CI [0.6522, 0.7360])\n",
            "Epoch 33 | Train Loss: 0.2653 | Test MAE: 0.6618 (95% CI [0.6329, 0.6901]) | Test RMSE: 0.7912 (95% CI [0.7555, 0.8251])\n",
            "Epoch 34 | Train Loss: 0.2904 | Test MAE: 0.4699 (95% CI [0.4422, 0.4978]) | Test RMSE: 0.6194 (95% CI [0.5819, 0.6577])\n",
            "Epoch 35 | Train Loss: 0.2662 | Test MAE: 0.4937 (95% CI [0.4672, 0.5217]) | Test RMSE: 0.6406 (95% CI [0.6040, 0.6782])\n",
            "Epoch 36 | Train Loss: 0.2549 | Test MAE: 0.4500 (95% CI [0.4228, 0.4798]) | Test RMSE: 0.6118 (95% CI [0.5729, 0.6551])\n",
            "Epoch 37 | Train Loss: 0.2495 | Test MAE: 0.6109 (95% CI [0.5825, 0.6386]) | Test RMSE: 0.7403 (95% CI [0.7069, 0.7721])\n",
            "Epoch 38 | Train Loss: 0.2354 | Test MAE: 0.4695 (95% CI [0.4432, 0.4982]) | Test RMSE: 0.6184 (95% CI [0.5808, 0.6578])\n",
            "Epoch 39 | Train Loss: 0.2450 | Test MAE: 0.4808 (95% CI [0.4535, 0.5102]) | Test RMSE: 0.6412 (95% CI [0.6028, 0.6836])\n"
          ]
        }
      ],
      "source": [
        "history = {}\n",
        "N = 40\n",
        "for epoch in range(1, N):\n",
        "    tr_loss = train(model, train_loader, optimizer, loss_fn)\n",
        "    metrics = evaluate_with_ci(model, test_loader)\n",
        "    print(f\"Epoch {epoch:02d} | Train Loss: {tr_loss:.4f} | \"\n",
        "          f\"Test MAE: {metrics['mae']:.4f} (95% CI [{metrics['mae_ci'][0]:.4f}, {metrics['mae_ci'][1]:.4f}]) | \"\n",
        "          f\"Test RMSE: {metrics['rmse']:.4f} (95% CI [{metrics['rmse_ci'][0]:.4f}, {metrics['rmse_ci'][1]:.4f}])\")\n",
        "    history[epoch] = metrics\n",
        "    scheduler.step(metrics['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhNtZfkfCM9m",
        "outputId": "30eb93ad-3aa3-43e0-d6b7-63098effac05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************\n",
            "Test MAE: 0.4808 (95% CI [0.4535, 0.5102])\n",
            "Test RMSE: 0.6412 (95% CI [0.6028, 0.6836])\n",
            "********************\n"
          ]
        }
      ],
      "source": [
        "final = history[N-1]\n",
        "print(\"*\"*20)\n",
        "print(f\"Test MAE: {final['mae']:.4f} (95% CI [{final['mae_ci'][0]:.4f}, {final['mae_ci'][1]:.4f}])\")\n",
        "print(f\"Test RMSE: {final['rmse']:.4f} (95% CI [{final['rmse_ci'][0]:.4f}, {final['rmse_ci'][1]:.4f}])\")\n",
        "print(\"*\"*20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QDfZgRTaEak"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
