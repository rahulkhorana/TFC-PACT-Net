{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M0suAYOT5R-N"
      },
      "outputs": [],
      "source": [
        "# Standard library\n",
        "from collections import defaultdict\n",
        "from typing import List, Tuple\n",
        "import importlib.resources as pkg_resources\n",
        "from multiprocessing.pool import ThreadPool\n",
        "\n",
        "# Third-party scientific stack\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import coo_matrix\n",
        "from scipy.sparse.linalg import eigsh\n",
        "\n",
        "# RDKit\n",
        "from rdkit import Chem\n",
        "\n",
        "# PyTorch core\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# PyTorch Geometric\n",
        "from torch_geometric.data import Data, Batch, DataLoader\n",
        "from torch_geometric.nn import GCNConv, GINConv, BatchNorm, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader as PyGDataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wginy3UChb_",
        "outputId": "a890fd99-8565-4658-aaf2-4ecd1c0a1860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "obXQxOveCM9l"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Fix all random seeds for reproducibility across Python, NumPy, and PyTorch.\n",
        "    \"\"\"\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(59)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fYyEoAXuCM9m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "\n",
        "class PolyatomicNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim,\n",
        "        graph_feat_dim=58,\n",
        "        hidden_dim=64,\n",
        "        output_dim=1,\n",
        "        num_layers=2,\n",
        "        heads=4,\n",
        "        dropout=0.2\n",
        "    ):\n",
        "        super(PolyatomicNet, self).__init__()\n",
        "        # Store graph feature dimension for reshaping\n",
        "        self.graph_feat_dim = graph_feat_dim\n",
        "\n",
        "        # Build GNN layers\n",
        "        self.gnn_layers = nn.ModuleList()\n",
        "        # First layer: multi-head\n",
        "        self.gnn_layers.append(\n",
        "            GATConv(input_dim, hidden_dim, heads=heads, dropout=dropout)\n",
        "        )\n",
        "        # Remaining layers: single-head\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.gnn_layers.append(\n",
        "                GATConv(hidden_dim * heads, hidden_dim, heads=1, dropout=dropout)\n",
        "            )\n",
        "\n",
        "        # Project graph-level features\n",
        "        self.graph_feat_proj = nn.Sequential(\n",
        "            nn.Linear(graph_feat_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # Final MLP head combines GNN output + graph_feats\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        # Handle empty edge_index: use self-loops\n",
        "        if edge_index.numel() == 0 or edge_index.size(1) == 0:\n",
        "            N = x.size(0)\n",
        "            edge_index = torch.stack([torch.arange(N, device=x.device), torch.arange(N, device=x.device)], dim=0)\n",
        "\n",
        "        # GNN forward\n",
        "        for gnn in self.gnn_layers:\n",
        "            x = F.elu(gnn(x, edge_index))\n",
        "\n",
        "        # Global pooling over nodes\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_dim]\n",
        "\n",
        "        # Project graph-level features\n",
        "        graph_feats_flat = data.graph_feats  # [batch_size, graph_feat_dim]\n",
        "        batch_size = int(batch.max().item()) + 1\n",
        "        g_feats = graph_feats_flat.view(batch_size, self.graph_feat_dim)\n",
        "        g_feats = self.graph_feat_proj(g_feats)\n",
        "\n",
        "        # Concatenate and final MLP\n",
        "        out = torch.cat([x, g_feats], dim=1)\n",
        "        out = self.fc(out)\n",
        "        return out.view(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Hh5vLiQ8CM9m"
      },
      "outputs": [],
      "source": [
        "def collate_with_graph_feats(batch_list):\n",
        "    graph_feats = torch.stack([data.graph_feats for data in batch_list], dim=0)\n",
        "    for data in batch_list:\n",
        "        del data.graph_feats\n",
        "    batched = Batch.from_data_list(batch_list)\n",
        "    batched.graph_feats = graph_feats\n",
        "    return batched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "daTRiHSFCM9m"
      },
      "outputs": [],
      "source": [
        "from torch.amp import autocast, GradScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "scaler_grad = GradScaler()\n",
        "\n",
        "def train(model, loader, optimizer, loss_fn, scaler=scaler_grad, accum_steps=8):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, batch in enumerate(loader):\n",
        "        batch = batch.to(device)\n",
        "        with autocast(device_type='cuda', dtype=torch.float16):\n",
        "            output = model(batch)\n",
        "            loss = loss_fn(output, batch.y.view(-1)) / accum_steps\n",
        "\n",
        "        scaler_grad.scale(loss).backward()\n",
        "\n",
        "        if (i + 1) % accum_steps == 0 or (i + 1 == len(loader)):\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item() * batch.num_graphs * accum_steps\n",
        "\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def compute_metrics_with_ci(trues, preds, n_boot=2000, alpha=0.05, seed=42):\n",
        "    trues = np.array(trues)\n",
        "    preds = np.array(preds)\n",
        "    mae = mean_absolute_error(trues, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "\n",
        "    rng = np.random.RandomState(seed)\n",
        "    mae_samples, rmse_samples = [], []\n",
        "    n = len(trues)\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.randint(0, n, n)\n",
        "        t, p = trues[idx], preds[idx]\n",
        "        mae_samples.append(mean_absolute_error(t, p))\n",
        "        rmse_samples.append(np.sqrt(mean_squared_error(t, p)))\n",
        "\n",
        "    lower, upper = 100 * alpha / 2, 100 * (1 - alpha / 2)\n",
        "    mae_ci = (np.percentile(mae_samples, lower), np.percentile(mae_samples, upper))\n",
        "    rmse_ci = (np.percentile(rmse_samples, lower), np.percentile(rmse_samples, upper))\n",
        "    return {'mae': mae, 'mae_ci': mae_ci, 'rmse': rmse, 'rmse_ci': rmse_ci}\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad(), autocast(device_type='cuda', dtype=torch.float16):\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch)\n",
        "            preds.append(out.view(-1))\n",
        "            trues.append(batch.y.view(-1))\n",
        "    preds = torch.cat(preds)\n",
        "    trues = torch.cat(trues)\n",
        "    return torch.sqrt(torch.mean((preds - trues) ** 2)).item()\n",
        "\n",
        "def evaluate_with_ci(model, loader):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad(), autocast(device_type='cuda', dtype=torch.float16):\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch)\n",
        "            y_true = batch.y.view(-1).cpu().tolist()\n",
        "            y_pred = out.view(-1).cpu().tolist()\n",
        "            trues.extend(y_true)\n",
        "            preds.extend(y_pred)\n",
        "    return compute_metrics_with_ci(trues, preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b7jK5FEjCM9m"
      },
      "outputs": [],
      "source": [
        "loading = True\n",
        "if loading:\n",
        "    all_data = torch.load('/content/drive/MyDrive/all_data_lipophil_enriched.pt', weights_only=False)\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    ys = np.array([d.y.item() for d in all_data]).reshape(-1, 1)\n",
        "    ys_scaled = scaler.fit_transform(ys)\n",
        "    for i, d in enumerate(all_data):\n",
        "        d.y = torch.tensor([ys_scaled[i][0]], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JoL1_anJb0rM"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aT9Ljr-SgTsE"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*An output with one or more elements was resized.*\")\n",
        "warnings.filterwarnings(\"ignore\", message=\".*FutureWarning:.*\")\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.optim.lr_scheduler\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_ZBbQn-98XEu"
      },
      "outputs": [],
      "source": [
        "data_list = all_data\n",
        "from torch_geometric.loader import DataLoader\n",
        "train_n = int(0.8*len(data_list))\n",
        "train_ds, test_ds = torch.utils.data.random_split(data_list, [train_n,len(data_list)-train_n])\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=8, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=16)\n",
        "\n",
        "input_dim = all_data[0].x.size(1)\n",
        "model     = PolyatomicNet(input_dim=input_dim)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', patience=10, factor=0.5, verbose=True\n",
        ")\n",
        "loss_fn   = nn.SmoothL1Loss(beta=0.5)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XchdS-ZoCM9m",
        "outputId": "7aadf298-28ad-4dbb-af5b-e6ba718605eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train Loss: 0.6222 | Test MAE: 0.7606 (95% CI [0.7189, 0.8018]) | Test RMSE: 0.9735 (95% CI [0.9211, 1.0230])\n",
            "Epoch 02 | Train Loss: 0.6076 | Test MAE: 0.7551 (95% CI [0.7178, 0.7941]) | Test RMSE: 0.9431 (95% CI [0.8970, 0.9887])\n",
            "Epoch 03 | Train Loss: 0.5994 | Test MAE: 0.7489 (95% CI [0.7114, 0.7874]) | Test RMSE: 0.9372 (95% CI [0.8905, 0.9832])\n",
            "Epoch 04 | Train Loss: 0.5988 | Test MAE: 0.7475 (95% CI [0.7098, 0.7868]) | Test RMSE: 0.9405 (95% CI [0.8930, 0.9875])\n",
            "Epoch 05 | Train Loss: 0.5968 | Test MAE: 0.7461 (95% CI [0.7079, 0.7855]) | Test RMSE: 0.9391 (95% CI [0.8917, 0.9861])\n",
            "Epoch 06 | Train Loss: 0.5979 | Test MAE: 0.7514 (95% CI [0.7140, 0.7901]) | Test RMSE: 0.9399 (95% CI [0.8934, 0.9861])\n",
            "Epoch 07 | Train Loss: 0.5990 | Test MAE: 0.7454 (95% CI [0.7072, 0.7848]) | Test RMSE: 0.9384 (95% CI [0.8907, 0.9852])\n",
            "Epoch 08 | Train Loss: 0.5987 | Test MAE: 0.7483 (95% CI [0.7106, 0.7871]) | Test RMSE: 0.9383 (95% CI [0.8910, 0.9847])\n",
            "Epoch 09 | Train Loss: 0.5980 | Test MAE: 0.7456 (95% CI [0.7073, 0.7850]) | Test RMSE: 0.9385 (95% CI [0.8909, 0.9853])\n",
            "Epoch 10 | Train Loss: 0.5975 | Test MAE: 0.7430 (95% CI [0.7036, 0.7827]) | Test RMSE: 0.9394 (95% CI [0.8921, 0.9862])\n",
            "Epoch 11 | Train Loss: 0.5971 | Test MAE: 0.7454 (95% CI [0.7073, 0.7849]) | Test RMSE: 0.9382 (95% CI [0.8906, 0.9850])\n",
            "Epoch 12 | Train Loss: 0.5974 | Test MAE: 0.7462 (95% CI [0.7080, 0.7851]) | Test RMSE: 0.9368 (95% CI [0.8900, 0.9833])\n",
            "Epoch 13 | Train Loss: 0.5966 | Test MAE: 0.7446 (95% CI [0.7061, 0.7840]) | Test RMSE: 0.9375 (95% CI [0.8900, 0.9844])\n",
            "Epoch 14 | Train Loss: 0.5976 | Test MAE: 0.7432 (95% CI [0.7040, 0.7828]) | Test RMSE: 0.9375 (95% CI [0.8902, 0.9839])\n",
            "Epoch 15 | Train Loss: 0.5966 | Test MAE: 0.7482 (95% CI [0.7106, 0.7864]) | Test RMSE: 0.9359 (95% CI [0.8895, 0.9819])\n",
            "Epoch 16 | Train Loss: 0.5965 | Test MAE: 0.7460 (95% CI [0.7079, 0.7853]) | Test RMSE: 0.9397 (95% CI [0.8919, 0.9870])\n",
            "Epoch 17 | Train Loss: 0.5973 | Test MAE: 0.7437 (95% CI [0.7049, 0.7827]) | Test RMSE: 0.9357 (95% CI [0.8884, 0.9819])\n",
            "Epoch 18 | Train Loss: 0.5988 | Test MAE: 0.7436 (95% CI [0.7047, 0.7829]) | Test RMSE: 0.9374 (95% CI [0.8898, 0.9841])\n",
            "Epoch 19 | Train Loss: 0.5974 | Test MAE: 0.7433 (95% CI [0.7040, 0.7828]) | Test RMSE: 0.9372 (95% CI [0.8899, 0.9834])\n",
            "Epoch 20 | Train Loss: 0.5963 | Test MAE: 0.7453 (95% CI [0.7071, 0.7847]) | Test RMSE: 0.9374 (95% CI [0.8901, 0.9845])\n",
            "Epoch 21 | Train Loss: 0.5962 | Test MAE: 0.7423 (95% CI [0.7029, 0.7820]) | Test RMSE: 0.9392 (95% CI [0.8919, 0.9857])\n",
            "Epoch 22 | Train Loss: 0.5976 | Test MAE: 0.7437 (95% CI [0.7047, 0.7827]) | Test RMSE: 0.9360 (95% CI [0.8888, 0.9823])\n",
            "Epoch 23 | Train Loss: 0.5963 | Test MAE: 0.7486 (95% CI [0.7109, 0.7872]) | Test RMSE: 0.9381 (95% CI [0.8908, 0.9846])\n",
            "Epoch 24 | Train Loss: 0.5987 | Test MAE: 0.7470 (95% CI [0.7091, 0.7856]) | Test RMSE: 0.9365 (95% CI [0.8897, 0.9830])\n",
            "Epoch 25 | Train Loss: 0.5970 | Test MAE: 0.7458 (95% CI [0.7076, 0.7845]) | Test RMSE: 0.9355 (95% CI [0.8891, 0.9818])\n",
            "Epoch 26 | Train Loss: 0.5969 | Test MAE: 0.7423 (95% CI [0.7029, 0.7820]) | Test RMSE: 0.9401 (95% CI [0.8925, 0.9870])\n",
            "Epoch 27 | Train Loss: 0.5976 | Test MAE: 0.7451 (95% CI [0.7068, 0.7842]) | Test RMSE: 0.9364 (95% CI [0.8897, 0.9829])\n",
            "Epoch 28 | Train Loss: 0.5963 | Test MAE: 0.7426 (95% CI [0.7032, 0.7826]) | Test RMSE: 0.9400 (95% CI [0.8924, 0.9871])\n",
            "Epoch 29 | Train Loss: 0.5964 | Test MAE: 0.7437 (95% CI [0.7046, 0.7837]) | Test RMSE: 0.9397 (95% CI [0.8919, 0.9873])\n",
            "Epoch 30 | Train Loss: 0.5960 | Test MAE: 0.7421 (95% CI [0.7028, 0.7809]) | Test RMSE: 0.9354 (95% CI [0.8882, 0.9813])\n",
            "Epoch 31 | Train Loss: 0.5957 | Test MAE: 0.7484 (95% CI [0.7105, 0.7863]) | Test RMSE: 0.9358 (95% CI [0.8892, 0.9810])\n",
            "Epoch 32 | Train Loss: 0.5953 | Test MAE: 0.7422 (95% CI [0.7030, 0.7816]) | Test RMSE: 0.9376 (95% CI [0.8901, 0.9844])\n",
            "Epoch 33 | Train Loss: 0.5951 | Test MAE: 0.7492 (95% CI [0.7115, 0.7875]) | Test RMSE: 0.9375 (95% CI [0.8906, 0.9832])\n",
            "Epoch 34 | Train Loss: 0.5964 | Test MAE: 0.7473 (95% CI [0.7095, 0.7852]) | Test RMSE: 0.9353 (95% CI [0.8885, 0.9804])\n",
            "Epoch 35 | Train Loss: 0.5962 | Test MAE: 0.7445 (95% CI [0.7058, 0.7831]) | Test RMSE: 0.9341 (95% CI [0.8874, 0.9800])\n",
            "Epoch 36 | Train Loss: 0.5968 | Test MAE: 0.7520 (95% CI [0.7144, 0.7898]) | Test RMSE: 0.9388 (95% CI [0.8918, 0.9838])\n",
            "Epoch 37 | Train Loss: 0.5960 | Test MAE: 0.7432 (95% CI [0.7045, 0.7828]) | Test RMSE: 0.9371 (95% CI [0.8900, 0.9843])\n",
            "Epoch 38 | Train Loss: 0.5964 | Test MAE: 0.7455 (95% CI [0.7075, 0.7842]) | Test RMSE: 0.9348 (95% CI [0.8885, 0.9804])\n",
            "Epoch 39 | Train Loss: 0.5953 | Test MAE: 0.7468 (95% CI [0.7089, 0.7849]) | Test RMSE: 0.9352 (95% CI [0.8884, 0.9800])\n"
          ]
        }
      ],
      "source": [
        "history = {}\n",
        "N = 40\n",
        "for epoch in range(1, N):\n",
        "    tr_loss = train(model, train_loader, optimizer, loss_fn)\n",
        "    metrics = evaluate_with_ci(model, test_loader)\n",
        "    print(f\"Epoch {epoch:02d} | Train Loss: {tr_loss:.4f} | \"\n",
        "          f\"Test MAE: {metrics['mae']:.4f} (95% CI [{metrics['mae_ci'][0]:.4f}, {metrics['mae_ci'][1]:.4f}]) | \"\n",
        "          f\"Test RMSE: {metrics['rmse']:.4f} (95% CI [{metrics['rmse_ci'][0]:.4f}, {metrics['rmse_ci'][1]:.4f}])\")\n",
        "    history[epoch] = metrics\n",
        "    scheduler.step(metrics['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhNtZfkfCM9m",
        "outputId": "7ac83826-69fc-4be4-d7cb-5a15ff052169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************\n",
            "Test MAE: 0.7468 (95% CI [0.7089, 0.7849])\n",
            "Test RMSE: 0.9352 (95% CI [0.8884, 0.9800])\n",
            "********************\n"
          ]
        }
      ],
      "source": [
        "final = history[N-1]\n",
        "print(\"*\"*20)\n",
        "print(f\"Test MAE: {final['mae']:.4f} (95% CI [{final['mae_ci'][0]:.4f}, {final['mae_ci'][1]:.4f}])\")\n",
        "print(f\"Test RMSE: {final['rmse']:.4f} (95% CI [{final['rmse_ci'][0]:.4f}, {final['rmse_ci'][1]:.4f}])\")\n",
        "print(\"*\"*20)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
